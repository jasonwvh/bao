### **Literature Review: The Convergence of Agentic Orchestration, Bayesian Decision Theory, and Human-AI Collaboration in NIDS**

The escalating sophistication of cyber threats, particularly zero-day exploits and polymorphic malware, has rendered traditional, monolithic Network Intrusion Detection Systems (NIDS) insufficient. In response, the field is shifting toward **Agentic AI**—autonomous systems capable of goal-directed planning and tool use,. However, a critical challenge remains: how to orchestrate these decentralized agents rationally under uncertainty. This review examines three converging sub-fields—Agent Orchestration, Bayesian Decision Theory, and Human-AI Collaboration—to expose the gap necessitating a **Bayesian Agent Orchestrator (BAO)**.

#### **1. Agent Orchestration: From Architecture to Governance**
Recent literature emphasizes the structural evolution of Multi-Agent Systems (MAS) into "Agentic AI." **Malatji (2025)** provides a foundational *AI Agent Taxonomy and Decision Framework (AIATDF)*, aligning agent types (reactive, cognitive, learning) with the NIST Cybersecurity Framework 2.0. This work is crucial for categorizing *what* agents can do but notes a lack of mechanisms for real-time, mathematically rigorous decision-making during agent selection.

To manage these agents, **Suggu (2025)** introduces the *Model-Control-Policy (MCP)* governance model. Suggu argues that a distinct "Control Layer" is essential to supervise agent autonomy and prevent "runaway execution" or adversarial manipulation, a bottleneck also identified by **Shrestha et al. (2025)** in industrial automation contexts. While Suggu defines the *need* for control, the specific algorithmic logic for this control layer remains open for definition.

On the implementation side, **Alba Torres et al. (2026)** developed *cyberSPADE*, a hierarchical MAS that reduces communication latency between "Network Defender" and "Forensic" swarms,. Similarly, **Du et al. (2024)** reviewed context-aware MAS, highlighting that while agents can perceive environment changes, integrating this awareness into a unified decision framework remains a challenge. These studies confirm that while the *infrastructure* for distributed defense exists, the *orchestration logic* often relies on static protocols rather than probabilistic reasoning.

#### **2. Bayesian Decision Theory and Value of Information (VoI)**
The theoretical cornerstone for the proposed BAO is found in the position paper by **Papamarkou et al. (2024)**, which argues that Agentic AI systems must make "Bayes-consistent" decisions,. They propose a **Bayesian controller layer** that maintains a belief state over task-relevant latent variables (e.g., threat presence) and selects actions based on expected utility. This aligns with **Jackson et al. (2022)**, who formalized **Value of Information (VoI)** methods to quantify the benefits of collecting further evidence before making a decision.

In the NIDS domain, **Kim, Dán, and Zhu (2024)** successfully applied this VoI logic to **alert prioritization**. By treating detection as an active learning problem within a Hidden Markov Model (HMM), they reduced detection time by 79%, proving that probabilistic prioritization is superior to static rules. **Wei and Dong (2025)** further demonstrated the power of Bayesian Networks (BN) by integrating them with Logistic Regression to model causal dependencies in vulnerability data, achieving 97% accuracy in risk assessment. Additionally, **Khosravi-Farmad and Ghaemi-Bafghi (2020)** utilized Bayesian Decision Networks (BDN) to optimize security countermeasure selection under budget constraints.

These works collectively validate Bayesian methods for *individual* tasks (alert triage, risk assessment). However, there is a gap in applying this rigorous calculus to the **real-time orchestration** of the agentic workforce defined by Malatji and Alba Torres.

#### **3. Human-AI Collaboration: The Uncertainty Loop**
The final pillar is the integration of human expertise. **Hao et al. (2025)** describe successful Human-AI collaboration as "institutional co-production," where AI handles data velocity while humans provide contextual judgment. **Tilbury and Flowerday (2024)** warn that without intelligent filtering, "alert fatigue" leads to automation bias, where analysts uncritically accept AI outputs.

**de Nascimento and Hou (2025)** operationalized this in NIDS through an **uncertainty-aware CNN-LSTM** model. Their system routes high-entropy (uncertain) predictions to human analysts, significantly improving the detection of rare attacks while keeping the human workload manageable. This resonates with **Ali et al. (2025)**, who compared Deep Learning vs. Machine Learning in NIDS, concluding that while DL models (like CNNs) are powerful, they require mechanisms to handle false positives effectively.

### **Comparative Analysis Table**

| **Author(s) & Year** | **Research Focus** | **Methodology** | **Dataset / Context** | **Key Findings** | **Strengths** | **Weaknesses / Limitations** |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Papamarkou et al. (2024)** | Bayesian Control for Agentic AI | Theoretical Framework / Position Paper | General Agentic AI Systems | Agent control layers should maintain belief states and use expected utility/VoI for action selection. | Establishes the theoretical necessity of Bayesian logic in agent orchestration. | High-level conceptual framework; lacks specific NIDS empirical validation. |
| **Kim, Dán, & Zhu (2024)** | HITL Intrusion Detection | Active Learning, HMM, Sequential Hypothesis Testing | Synthetic Attack Graphs / Alert Streams | Dynamic prioritization (Max Ratio/KL) reduces detection time by 79% vs. static baselines. | Rigorous mathematical formulation of VoI for alert triage; models human error. | Focuses on *alert* prioritization rather than orchestrating a multi-agent *tool* ecosystem. |
| **Malatji (2025)** | AI Agent Framework for NIDS | Taxonomy Development, NIST CSF 2.0 Mapping | NIST Cybersecurity Framework | Maps agent types (Reactive, Cognitive) to NIST functions; defines autonomy levels. | Provides governance structure aligning agents with industry standards. | Structural framework; lacks the mathematical engine for real-time agent selection. |
| **Suggu (2025)** | Governance of Agentic AI | Model-Control-Policy (MCP) Framework | SOC Operations / Governance | A "Control Layer" is required to supervise Model outputs and enforce Policy constraints. | Explicitly defines the architectural layer where a Bayesian Orchestrator would reside. | Focuses on governance/safety guardrails rather than optimization algorithms. |
| **Alba Torres et al. (2026)** | Multi-Agent Cyberdefense | Hierarchical MAS (SPADE platform) | Virtualized Network Environment | Hierarchical swarms enable low-latency coordination and scalable scanning. | Validates communication efficiency in distributed agent architectures. | Focuses on messaging infrastructure rather than decision-theoretic logic. |
| **de Nascimento & Hou (2025)** | Uncertainty-Aware NIDS | CNN-LSTM, cWGAN-GP, Entropy Gating | CIC-IDS2017, CIC-IoT2023 | High-entropy predictions should be routed to humans; GANs improve rare attack detection. | Demonstrates practical effectiveness of uncertainty-based deferral (HITL). | Uses a monolithic model rather than an orchestrated multi-agent ensemble. |
| **Wei & Dong (2025)** | Risk Assessment | Bayesian Networks + Logistic Regression | CISA Known Exploited Vulnerabilities | Hybrid BN-LR model captures causal dependencies of vulnerability factors (97% accuracy). | Strong causal modeling of static risk factors. | Static assessment focus; does not address real-time traffic or active agent deployment. |
| **Hao et al. (2025)** | Human-AI Sensemaking | Qualitative Case Study, Cognitive Mapping | Supply Chain / Ops Management | Collaboration requires "institutional co-production"; humans handle ambiguity/ethics. | Rich insights into the human role in algorithmic decision-making. | Domain is OSCM, not NIDS; lacks quantitative models for measuring collaboration efficiency. |
| **Shrestha et al. (2025)** | Agentic AI Security | Systematic Review & Simulation | Industrial Automation (CrewAI) | Agentic systems are vulnerable to loops/injection; require robust anomaly detection. | Highlights specific security bottlenecks in current agent frameworks. | Focuses on protecting the agents, not using agents *as* the security orchestrator. |
| **Lalropuia et al. (2025)** | Insider Threat Mitigation | Bayesian Game Theory (Incomplete Information) | Construction / CDE Data | Bayesian Nash Equilibrium predicts malicious behavior under incomplete information. | Applies Bayesian Game Theory effectively to model adversarial interactions. | Specific to insider threats; assumes rational actors which may not map to malware. |
| **Tilbury & Flowerday (2024)** | SOC Automation | Scoping Review / Thematic Analysis | SOC Literature | Automation must address "alert fatigue"; synergy between analyst and machine is critical. | Highlights socio-technical constraints (fatigue, bias) relevant to orchestration. | Qualitative; does not provide a quantitative model for human-machine teaming. |
| **Jackson et al. (2022)** | Value of Information (VoI) | Decision-Theoretic Review | Health Policy / General | VoI estimates expected benefits of collecting further info to reduce decision uncertainty. | Foundational math for the "Value of Information" component of the orchestrator. | Context is health policy; requires adaptation to the high-velocity NIDS domain. |
| **Khosravi-Farmad et al. (2020)** | Risk Mitigation | Bayesian Decision Networks (BDN) | Network Security Simulation | BDNs enable cost-benefit analysis for risk mitigation under budget constraints. | Demonstrates utility of BDNs for cost-aware security decisions. | Focuses on mitigation planning rather than real-time detection orchestration. |
| **Ali et al. (2025)** | DL vs. ML for NIDS | Comparative Study | CIC-IDS2017 | Deep Learning outperforms ML but requires careful handling of false positives/resources. | Validates the need for advanced models (like the agents in BAO). | Does not propose an orchestration layer to manage these models. |
| **Du et al. (2024)** | Context-Aware MAS | Survey | General Multi-Agent Systems | Context awareness is pivotal for MAS robustness in dynamic environments. | thorough review of context-aware techniques. | General survey; lacks a specific unified Bayesian framework proposal. |

### **Outcome: Exposing the Gap and Justifying the Bayesian Agent Orchestrator (BAO)**

**The Gap in Current Literature:**
The literature reveals a functional schism. On one side, **architectural research** (Malatji, Alba Torres, Suggu) successfully defines the *body* of Agentic AI—hierarchies, communication protocols, and governance layers—but relies on deterministic or static logic for coordination. On the other side, **algorithmic research** (Kim, Wei, de Nascimento) uses Bayesian methods and uncertainty quantification to improve *specific* detection tasks, but these operate as standalone models or alert prioritizers, not as system-wide orchestrators of a diverse agent ecosystem.

**There is currently no unified framework** that:
1.  **Orchestrates** a diverse ecosystem of specialized detectors (as defined by Malatji).
2.  Maintains a **central belief state** regarding the network's threat status (as proposed by Papamarkou).
3.  Uses **Value of Information (VoI)** (as formalized by Jackson) to dynamically trigger expensive agents or human analysts only when the expected utility justifies the cost.

**Justification for the Bayesian Agent Orchestrator (BAO):**
The BAO is justified as the necessary "Control Layer" (Suggu) that bridges these disciplines.
*   **Rationality:** Inspired by Papamarkou et al., the BAO treats agents as noisy sensors, updating a central belief state rather than naively aggregating votes.
*   **Cost-Efficiency:** By extending Kim et al.'s VoI logic, the BAO addresses the bottlenecks identified by Shrestha and Tilbury, reducing computational waste and alert fatigue by mathematically validating the need for every action.
*   **Safety:** It provides a rigorous mechanism to enforce the safety policies demanded by Malatji and de Nascimento, ensuring that autonomous actions (like blocking traffic) are taken only when Bayesian confidence exceeds strict thresholds.